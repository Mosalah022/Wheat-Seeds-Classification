# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XkIm9gqH6Ep1MDrnoqCVAopAlQhU42PB

#Cover Page

**Developed by:**

**Mohamed Fathi - 41810059**

**Ahmed Saber - 41810077**

#Import the dataset from drive
"""

!gdown --id 1MbUWPsEZJ_Dana5RC07wUGTIgzN92Uld

"""#Importing libraries"""

import pandas as pd
import seaborn as sns
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix,accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

"""# show how the data looks like"""

data = pd.read_csv('seeds.csv')
data.head(5)

"""# Check if all data are numbers and if there is a relations between the data

"""

data.dtypes

data.info()

data.columns

"""#Heatmap"""

x,y = plt.subplots(figsize=(12,9))
sns.heatmap(data.corr(),cmap='YlGnBu',square=True,linewidth=.5,annot=True)
plt.show()

"""# Check for the null """

data.isna().any()
data.isnull().sum()
data.dropna()

"""# show mean, max , min so handle the data if there is a gap between 75% and max  """

data.describe()

"""# check for the outlier"""

data.hist(bins=50,figsize=(20,15))
plt.show()

data.shape

"""**drop the outlier**"""

# Q1 = data.quantile(0.25)
# Q3 = data.quantile(0.75)
# IQR = Q3 - Q1
# print (IQR)
# data = data[~((data < (Q1 - 1.5 *  IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]
# print (data.shape)

# data.hist(bins=50,figsize=(20,15))
# plt.show()

"""#Normalization"""

df = data.drop('Type', axis=1)
df_norm = (df-df.min())/(df.max()-df.min())
df_norm = pd.concat((df_norm, data.Type), 1)
df_norm.head()

"""#Start Split the data and train"""

X_train, X_test, y_train, y_test = train_test_split(df_norm.drop('Type', axis=1), df_norm['Type'], test_size = 0.20)
print(len(X_train), "train +", len(X_test), "valid")

"""**Using KNN ( k-nearest neighbors ) for trainning** """

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train,y_train)

y_pred = knn.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

sns.heatmap(cm, annot=True)
plt.xlabel('Prediction')
plt.ylabel('Truth')

"""**Accuracy** """

var="%"
print("Accuracy: %0.1f" % (knn.score(X_test,y_test)*100), var[0])

"""#find the mean square error"""

lin_mse = mean_squared_error(y_test, y_pred)
lin_rmse = np.sqrt(lin_mse)
lin_rmse

lin_mae = mean_absolute_error(y_test, y_pred)
lin_mae