# -*- coding: utf-8 -*-
"""ML_Project_Linear.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_-DQzzaqsaku9yZi6bxks_k6Olj70DZA

#Cover Page

**Developed by:**

**Fatma Mohamed Ali - 41810121**

**Mohamed Salah Eldin - 41810303**

#Import the dataset from drive
"""

!gdown --id 1MbUWPsEZJ_Dana5RC07wUGTIgzN92Uld

"""#Importing libraries"""

import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns 
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

"""# show how the data looks like"""

df = pd.read_csv("seeds.csv")
df.head()

"""# Check if all data are numbers and if there is a relations between the data

"""

df.dtypes

df.info()

df.columns

#from sklearn.preprocessing import LabelEncoder
#encoder = LabelEncoder()

"""#Heatmap"""

#df.corr()
x,y = plt.subplots(figsize=(12,9))
sns.heatmap(df.corr(),cmap='YlGnBu',square=True,linewidth=.5,annot=True)
plt.show()

"""# Check for the null """

df.isna().any()
#df.isnull().sum()
df.dropna()

"""# show mean, max , min so handle the data if there is a gap between 75% and max  

"""

df.describe()

"""# check for the outlier"""

"""
df['Area'].skew()
df['Asymmetry.Coeff'].skew()
plt.boxplot(df['Kernel.Groove'])
plt.show()
"""
df.hist(bins=50,figsize=(20,15))
plt.show()

df.shape

"""**drop the outlier**

"""

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1
print (IQR)
df = df[~((df < (Q1 - 1.5 *  IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]
print (df.shape)

df.hist(bins=50,figsize=(20,15))
plt.show()

"""#Normalization"""

scaler=StandardScaler()
scaler.fit(df)
dataset=scaler.transform(df)
dataset

"""#Start Split the data and train"""

df_target = df["Type"]  #save target for training set
df = df.drop("Type", axis=1) #drop target for training set

"""**train_test_split imported from sklearn.model_selection**"""

"""
#split the data for training and validation
First Way to split data 
train_set_size= int(len (df) * 0.7)
train_set = df [:train_set_size][:]
valid_set = df [train_set_size:][:]

train_target = df_target [:train_set_size]
valid_target = df_target [train_set_size:]
print(len (train_set), "train +", len(valid_set), "valid")
"""
#second way
train_set, valid_set = train_test_split(df, test_size=0.2)
train_target, valid_target = train_test_split (df_target, test_size=0.2)
print(len(train_set), "train +", len(valid_set), "valid")

"""**Using linear model for trainning**

**LinearRegression imported from sklearn.linear_model**
"""

lin_reg = LinearRegression()
lin_reg.fit(train_set, train_target)

"""#find the mean square error

**mean_squared_error imported from from sklearn.metrics**

**np.sqrt imported from numpy**
"""

Type_predictions = lin_reg.predict(valid_set)
lin_mse = mean_squared_error(valid_target, Type_predictions)
lin_rmse = np.sqrt(lin_mse)
lin_rmse

"""**mean_absolute_error imported from from sklearn.metrics**

"""

lin_mae = mean_absolute_error(valid_target, Type_predictions)
lin_mae